# EP-010: Implement Lambda Functions for Real-time Services

**Status:** ğŸ”´ Not Started
**Priority:** ğŸ”¥ High
**Story Points:** 13
**Sprint:** Phase 3 - Real-time Services
**Assignee:** Backend Team
**Created:** 2025-12-16
**Type:** Feature

---

## ğŸ“‹ Overview

### User Story
**As a** platform operator
**I want** real-time Lambda-based services for experiment assignments and event processing
**So that** we can handle high-volume, low-latency operations with automatic scaling and minimal infrastructure management

### Business Value
- **Performance:** Sub-50ms experiment assignment latency
- **Scalability:** Automatic scaling for 100K+ requests/second
- **Cost:** Pay-per-use model reduces infrastructure costs by ~60%
- **Reliability:** Built-in fault tolerance and retry mechanisms

---

## ğŸ¯ Problem Statement

Currently, the platform has infrastructure defined for Lambda functions in CDK but lacks the actual Lambda function implementations. This creates a gap in the real-time services layer, preventing:

1. Fast, consistent experiment variant assignments
2. Real-time event collection and processing
3. High-throughput feature flag evaluations
4. Scalable assignment persistence to DynamoDB

### Current State
- âœ… AWS CDK infrastructure defined (`infrastructure/cdk/stacks/analytics_stack.py`, `compute_stack.py`)
- âœ… Kinesis streams configured
- âœ… DynamoDB tables defined
- âœ… Lambda IAM roles created
- âŒ Lambda function code not implemented
- âŒ Assignment service Lambda missing
- âŒ Event processor Lambda missing
- âŒ Real-time evaluation Lambda missing

---

## ğŸ”§ Technical Specifications

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Client Application                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”œâ”€â”€â”€ GET /assign â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚                              â”‚
               â””â”€â”€â”€ POST /events â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                              â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚           API Gateway / ALB                 â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚                â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Assignment Lambda  â”‚   â”‚ Event Processor      â”‚
            â”‚  (Python 3.11)      â”‚   â”‚ Lambda (Python 3.11) â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚                          â”‚
                      â”œâ”€â”€â”€â”€â”€â”€â”€â”€ Read â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                      â”‚                          â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   DynamoDB       â”‚      â”‚  Kinesis Stream   â”‚
              â”‚   Assignments    â”‚      â”‚  (Events)         â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚                          â”‚
                      â”‚                          â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   PostgreSQL     â”‚      â”‚  S3 Data Lake     â”‚
              â”‚   (Sync)         â”‚      â”‚  (Archive)        â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Lambda Functions to Implement

#### 1. **Assignment Lambda** (`backend/lambda/assignment/handler.py`)

**Purpose:** Handle experiment variant assignments using consistent hashing

**Inputs:**
```python
{
    "user_id": str,
    "experiment_key": str,
    "context": dict,  # User attributes for targeting
}
```

**Outputs:**
```python
{
    "variant": str,
    "experiment_id": str,
    "assignment_id": str,
    "timestamp": str,
}
```

**Logic:**
1. Validate experiment is ACTIVE
2. Evaluate targeting rules (if any)
3. Calculate variant using consistent hashing
4. Store assignment in DynamoDB
5. Async sync to PostgreSQL (if needed)
6. Return variant assignment

**Performance Requirements:**
- P50 latency: < 20ms
- P99 latency: < 50ms
- Throughput: 10K requests/second per Lambda

#### 2. **Event Processor Lambda** (`backend/lambda/events/handler.py`)

**Purpose:** Process incoming events from Kinesis stream

**Trigger:** Kinesis stream events (batch processing)

**Inputs:**
```python
{
    "Records": [
        {
            "kinesis": {
                "data": base64_encoded_event
            }
        }
    ]
}
```

**Logic:**
1. Decode and validate events
2. Enrich with assignment data
3. Aggregate metrics (if applicable)
4. Store in DynamoDB counters
5. Archive to S3 (via Firehose)
6. Handle errors and retries

**Performance Requirements:**
- Batch size: 100-500 events
- Processing latency: < 100ms per batch
- Error rate: < 0.1%

#### 3. **Feature Flag Evaluation Lambda** (`backend/lambda/feature_flags/handler.py`)

**Purpose:** Real-time feature flag evaluation with targeting

**Inputs:**
```python
{
    "flag_key": str,
    "user_id": str,
    "context": dict,
}
```

**Outputs:**
```python
{
    "enabled": bool,
    "variant": str | None,
    "reason": str,
}
```

**Logic:**
1. Fetch flag configuration (with caching)
2. Evaluate targeting rules
3. Apply rollout percentage
4. Return evaluation result
5. Record evaluation event (async)

**Performance Requirements:**
- P50 latency: < 15ms
- P99 latency: < 40ms
- Cache hit rate: > 95%

---

## ğŸ§ª Test-Driven Development Approach

This implementation follows **Test-Driven Development (TDD)** methodology:

### TDD Cycle (Red-Green-Refactor)

1. **ğŸ”´ RED:** Write failing test first
2. **ğŸŸ¢ GREEN:** Write minimal code to pass test
3. **ğŸ”µ REFACTOR:** Improve code while keeping tests passing
4. **â™»ï¸ REPEAT:** Continue for next feature

### Test Coverage Requirements

- **Unit Tests:** â‰¥85% code coverage
- **Integration Tests:** All critical paths tested
- **Edge Cases:** Comprehensive edge case handling
- **Performance Tests:** Latency and throughput benchmarks

### Test Categories

1. **Unit Tests** - Test individual functions in isolation
2. **Integration Tests** - Test Lambda with mocked AWS services
3. **Contract Tests** - Validate input/output schemas
4. **Performance Tests** - Benchmark latency and throughput
5. **End-to-End Tests** - Test complete workflows

---

## ğŸ“ Implementation Tasks

### Phase 1: Setup & Infrastructure (3 days) âœ… COMPLETED

- [x] **Task 1.1:** Create Lambda function directory structure
  ```bash
  backend/lambda/
  â”œâ”€â”€ assignment/
  â”‚   â”œâ”€â”€ handler.py
  â”‚   â”œâ”€â”€ requirements.txt
  â”‚   â””â”€â”€ tests/
  â”œâ”€â”€ events/
  â”‚   â”œâ”€â”€ handler.py
  â”‚   â”œâ”€â”€ requirements.txt
  â”‚   â””â”€â”€ tests/
  â”œâ”€â”€ feature_flags/
  â”‚   â”œâ”€â”€ handler.py
  â”‚   â”œâ”€â”€ requirements.txt
  â”‚   â””â”€â”€ tests/
  â””â”€â”€ shared/
      â”œâ”€â”€ __init__.py
      â”œâ”€â”€ utils.py
      â”œâ”€â”€ consistent_hash.py
      â””â”€â”€ models.py
  ```

- [x] **Task 1.2:** Create shared utilities module
  - âœ… Consistent hashing algorithm (MurmurHash3)
  - âœ… DynamoDB helpers (get/put operations)
  - âœ… Kinesis helpers (put/batch operations)
  - âœ… Logging utilities (JSON CloudWatch logging)
  - âœ… Pydantic data models for validation

- [x] **Task 1.3:** Write comprehensive documentation
  - âœ… README with architecture overview
  - âœ… Usage examples for shared utilities
  - âœ… API documentation for all functions

**Status:** âœ… COMPLETED (Commit: 0e03905)

---

### Phase 2: Assignment Lambda (4 days) - TDD Approach

#### Day 1: Write Tests for Core Assignment Logic

- [ ] **Task 2.1:** ğŸ”´ Write unit tests for consistent hashing
  ```python
  # Test: Same user+experiment always returns same variant
  # Test: Variant distribution matches allocation percentages (Â±2%)
  # Test: Traffic allocation excludes correct percentage
  # Test: Edge cases (empty variants, invalid allocation)
  ```

- [ ] **Task 2.2:** ğŸŸ¢ Implement consistent hashing to pass tests
  - Use shared `ConsistentHasher` from Phase 1
  - Ensure deterministic assignments
  - Validate allocation percentages

- [ ] **Task 2.3:** ğŸ”´ Write tests for experiment config validation
  ```python
  # Test: Valid experiment returns config
  # Test: Invalid experiment_key raises error
  # Test: DRAFT experiments are excluded
  # Test: PAUSED experiments return None
  ```

- [ ] **Task 2.4:** ğŸŸ¢ Implement config fetching and validation
  - Fetch from DynamoDB or cache
  - Validate experiment status
  - Handle missing experiments

#### Day 2: Write Tests for DynamoDB Integration

- [ ] **Task 2.5:** ğŸ”´ Write tests for assignment storage
  ```python
  # Test: Assignment stored with correct schema
  # Test: Duplicate assignment doesn't create new record
  # Test: TTL set correctly for cleanup
  # Test: DynamoDB errors handled gracefully
  ```

- [ ] **Task 2.6:** ğŸŸ¢ Implement DynamoDB assignment storage
  - Schema: `user_id`, `experiment_id`, `variant`, `timestamp`, `ttl`
  - Implement conditional writes (prevent duplicates)
  - Add TTL for 90-day cleanup
  - Error handling and retries

- [ ] **Task 2.7:** ğŸ”´ Write tests for assignment retrieval
  ```python
  # Test: Get existing assignment returns correct variant
  # Test: New user gets assigned variant
  # Test: Assignment consistency across calls
  ```

- [ ] **Task 2.8:** ğŸŸ¢ Implement assignment retrieval logic
  - Check DynamoDB for existing assignment
  - Create new assignment if not exists
  - Return consistent results

#### Day 3: Write Tests for Targeting Rules & Caching

- [ ] **Task 2.9:** ğŸ”´ Write tests for targeting rule evaluation
  ```python
  # Test: User matching rule gets assigned
  # Test: User not matching rule excluded
  # Test: Multiple rules evaluated correctly (AND/OR logic)
  # Test: Missing context attributes handled
  ```

- [ ] **Task 2.10:** ğŸŸ¢ Implement targeting rules evaluation
  - Reuse backend rules engine logic
  - Evaluate user context against rules
  - Handle complex conditions (AND, OR, NOT)

- [ ] **Task 2.11:** ğŸ”´ Write tests for caching layer
  ```python
  # Test: Experiment config cached after first fetch
  # Test: Cache invalidation after TTL
  # Test: Cache hit improves performance
  # Test: Cache miss falls back to DynamoDB
  ```

- [ ] **Task 2.12:** ğŸŸ¢ Implement Lambda warm-start caching
  - Cache experiment configs in global scope
  - TTL: 5 minutes
  - Cache targeting rules
  - Measure cache hit rate

#### Day 4: Write Tests for Error Handling & Handler Integration

- [ ] **Task 2.13:** ğŸ”´ Write tests for error scenarios
  ```python
  # Test: Invalid input returns 400
  # Test: Missing experiment returns 404
  # Test: DynamoDB failure returns 500
  # Test: Timeout handled gracefully
  ```

- [ ] **Task 2.14:** ğŸŸ¢ Implement error handling
  - Input validation with Pydantic
  - Graceful degradation for failures
  - Proper HTTP status codes
  - Structured error responses

- [ ] **Task 2.15:** ğŸ”´ Write integration tests for Lambda handler
  ```python
  # Test: Complete assignment flow (end-to-end)
  # Test: Performance benchmarks (< 50ms P99)
  # Test: Concurrent requests handled correctly
  ```

- [ ] **Task 2.16:** ğŸŸ¢ Implement Lambda handler function
  - Parse API Gateway event
  - Orchestrate assignment flow
  - Format response
  - Add CloudWatch logging

- [ ] **Task 2.17:** ğŸ”µ Refactor and optimize
  - Code review and cleanup
  - Performance optimizations
  - Documentation updates
  - Run all tests to ensure no regressions

### Phase 3: Event Processor Lambda (3 days) - TDD Approach

#### Day 1: Write Tests for Event Parsing & Validation

- [ ] **Task 3.1:** ğŸ”´ Write unit tests for Kinesis event parsing
  ```python
  # Test: Valid base64 event decoded correctly
  # Test: Batch of events parsed correctly
  # Test: Malformed base64 handled gracefully
  # Test: Invalid JSON returns error
  ```

- [ ] **Task 3.2:** ğŸŸ¢ Implement Kinesis event parsing
  - Decode base64-encoded data
  - Parse JSON payloads
  - Handle encoding errors
  - Return structured event list

- [ ] **Task 3.3:** ğŸ”´ Write tests for event schema validation
  ```python
  # Test: Valid event passes validation
  # Test: Missing required fields rejected
  # Test: Invalid event_type rejected
  # Test: Validation error messages clear
  ```

- [ ] **Task 3.4:** ğŸŸ¢ Implement event validation with Pydantic
  - Use `EventData` model from shared module
  - Validate required fields
  - Type checking
  - Return validation errors

#### Day 2: Write Tests for Event Enrichment & Aggregation

- [ ] **Task 3.5:** ğŸ”´ Write tests for event enrichment
  ```python
  # Test: Assignment data fetched and added
  # Test: Experiment metadata enriched
  # Test: Missing assignment handled
  # Test: Enrichment preserves original data
  ```

- [ ] **Task 3.6:** ğŸŸ¢ Implement event enrichment logic
  - Fetch assignment from DynamoDB
  - Add experiment metadata
  - Calculate derived fields
  - Handle missing data gracefully

- [ ] **Task 3.7:** ğŸ”´ Write tests for DynamoDB aggregation
  ```python
  # Test: Counter incremented atomically
  # Test: Multiple events aggregated correctly
  # Test: Time windows handled properly
  # Test: Concurrent updates don't conflict
  ```

- [ ] **Task 3.8:** ğŸŸ¢ Implement real-time metric aggregation
  - Atomic counter increments
  - Time-windowed aggregation (hourly, daily)
  - Use DynamoDB conditional updates
  - Handle race conditions

#### Day 3: Write Tests for Batch Processing & S3 Archival

- [ ] **Task 3.9:** ğŸ”´ Write tests for S3 archival
  ```python
  # Test: Events batched by size/time
  # Test: Data compressed with gzip
  # Test: Date partitioning correct (year/month/day/hour)
  # Test: S3 upload errors handled
  ```

- [ ] **Task 3.10:** ğŸŸ¢ Implement S3 archival
  - Batch events (max 1000 or 5MB)
  - Compress with gzip
  - Organize by date: `s3://bucket/year=2025/month=12/day=18/`
  - Error handling and retries

- [ ] **Task 3.11:** ğŸ”´ Write tests for batch processing logic
  ```python
  # Test: Partial batch failures handled
  # Test: Failed records sent to DLQ
  # Test: Successful records checkpointed
  # Test: Batch retry logic works
  ```

- [ ] **Task 3.12:** ğŸŸ¢ Implement batch processing with error handling
  - Process records in batches
  - Track successes and failures
  - Send failed records to DLQ
  - Return proper batch response

- [ ] **Task 3.13:** ğŸ”´ Write integration tests for handler
  ```python
  # Test: End-to-end Kinesis batch processing
  # Test: Performance: 500 events in < 100ms
  # Test: Error rate < 0.1%
  ```

- [ ] **Task 3.14:** ğŸŸ¢ Implement Lambda handler for Kinesis
  - Parse Kinesis records
  - Orchestrate processing pipeline
  - Handle errors gracefully
  - CloudWatch logging

- [ ] **Task 3.15:** ğŸ”µ Refactor and optimize
  - Parallel processing where possible
  - Optimize batch sizes
  - Code cleanup
  - Documentation

### Phase 4: Feature Flag Lambda (2 days) - TDD Approach

#### Day 1: Write Tests for Flag Evaluation Logic

- [ ] **Task 4.1:** ğŸ”´ Write unit tests for flag config fetching
  ```python
  # Test: Valid flag returns config
  # Test: Invalid flag_key returns 404
  # Test: Disabled flag returns False
  # Test: Config cached after first fetch
  ```

- [ ] **Task 4.2:** ğŸŸ¢ Implement flag configuration fetching
  - Fetch from DynamoDB or cache
  - Validate flag status
  - Handle missing flags
  - Cache hit/miss tracking

- [ ] **Task 4.3:** ğŸ”´ Write tests for rollout percentage logic
  ```python
  # Test: 0% rollout returns False for all users
  # Test: 100% rollout returns True for all users
  # Test: 50% rollout splits users evenly (Â±2%)
  # Test: Same user gets consistent result
  ```

- [ ] **Task 4.4:** ğŸŸ¢ Implement rollout percentage evaluation
  - Use consistent hashing for determinism
  - Calculate user bucket (0-100)
  - Compare to rollout percentage
  - Return boolean result

- [ ] **Task 4.5:** ğŸ”´ Write tests for targeting rules
  ```python
  # Test: User matching rule gets flag enabled
  # Test: User not matching rule gets flag disabled
  # Test: Multiple rules evaluated (AND/OR)
  # Test: Missing context handled gracefully
  ```

- [ ] **Task 4.6:** ğŸŸ¢ Implement targeting rules evaluation
  - Reuse rules engine from backend
  - Evaluate user context
  - Handle complex conditions
  - Return evaluation reason

#### Day 2: Write Tests for Caching & Handler Integration

- [ ] **Task 4.7:** ğŸ”´ Write tests for caching strategy
  ```python
  # Test: Cache hit returns config without DynamoDB call
  # Test: Cache miss fetches from DynamoDB
  # Test: TTL expiration invalidates cache
  # Test: Cache hit rate > 95%
  ```

- [ ] **Task 4.8:** ğŸŸ¢ Implement Lambda warm-start caching
  - Global cache for flag configs
  - TTL-based invalidation (5 min)
  - LRU eviction for memory limits
  - Cache metrics tracking

- [ ] **Task 4.9:** ğŸ”´ Write tests for evaluation tracking
  ```python
  # Test: Evaluation event recorded
  # Test: Event sent to Kinesis asynchronously
  # Test: Tracking failure doesn't block response
  # Test: Performance impact < 1ms
  ```

- [ ] **Task 4.10:** ğŸŸ¢ Implement async evaluation tracking
  - Create evaluation event
  - Send to Kinesis (fire and forget)
  - Don't block on Kinesis response
  - Error handling without failure

- [ ] **Task 4.11:** ğŸ”´ Write integration tests for handler
  ```python
  # Test: Complete flag evaluation flow
  # Test: Performance: < 40ms P99
  # Test: Cache hit rate measurement
  # Test: Concurrent evaluations
  ```

- [ ] **Task 4.12:** ğŸŸ¢ Implement Lambda handler
  - Parse API Gateway event
  - Orchestrate evaluation flow
  - Format response with reason
  - CloudWatch logging

- [ ] **Task 4.13:** ğŸ”µ Refactor and optimize
  - Minimize cold start time
  - Optimize cache lookups
  - Code cleanup
  - Documentation

---

### Phase 5: Comprehensive Testing & Optimization (3 days) - TDD Validation

#### Day 1: Unit Test Coverage & Edge Cases

- [ ] **Task 5.1:** âœ… Verify unit test coverage â‰¥85%
  ```bash
  pytest --cov=backend/lambda --cov-report=html
  # Coverage must be â‰¥85% for all Lambda functions
  ```

- [ ] **Task 5.2:** ğŸ”´ Write tests for edge cases
  ```python
  # Test: Extremely large payloads
  # Test: Unicode and special characters
  # Test: Concurrent Lambda invocations
  # Test: Memory limits and timeouts
  # Test: Cold start vs warm start performance
  ```

- [ ] **Task 5.3:** ğŸŸ¢ Implement edge case handling
  - Payload size validation
  - Character encoding handling
  - Concurrency controls
  - Timeout management

- [ ] **Task 5.4:** ğŸ”µ Refactor based on coverage gaps
  - Identify uncovered code paths
  - Add missing tests
  - Improve error handling
  - Update documentation

#### Day 2: Integration & Performance Testing

- [ ] **Task 5.5:** ğŸ”´ Write integration tests with AWS Local
  ```python
  # Test: DynamoDB Local integration
  # Test: Kinesis Local integration
  # Test: S3 mock integration
  # Test: End-to-end scenarios
  ```

- [ ] **Task 5.6:** ğŸŸ¢ Set up local AWS environment
  - DynamoDB Local for testing
  - LocalStack for Kinesis/S3
  - Docker Compose configuration
  - Test data seeding

- [ ] **Task 5.7:** ğŸ”´ Write performance benchmark tests
  ```python
  # Test: Assignment Lambda < 50ms P99
  # Test: Event Processor < 100ms per batch
  # Test: Feature Flag < 40ms P99
  # Test: Throughput: 10K RPS per function
  ```

- [ ] **Task 5.8:** ğŸŸ¢ Implement performance testing harness
  - Load generation with Locust/Artillery
  - Latency measurement (P50, P95, P99)
  - Throughput testing
  - Resource utilization tracking

- [ ] **Task 5.9:** ğŸ”µ Optimize based on benchmarks
  - Identify bottlenecks
  - Optimize slow code paths
  - Tune Lambda memory/timeout
  - Re-run benchmarks to validate

#### Day 3: Monitoring, Alerts & Final Validation

- [ ] **Task 5.10:** Implement CloudWatch dashboards
  - Lambda invocation metrics
  - Error rates and duration
  - Custom business metrics
  - Cache hit rates

- [ ] **Task 5.11:** Configure CloudWatch alarms
  - Error rate > 1% alert
  - P99 latency > threshold alert
  - DynamoDB throttling alert
  - Dead letter queue alert

- [ ] **Task 5.12:** âœ… Run full test suite
  ```bash
  # Run all tests: unit, integration, performance
  pytest backend/lambda/ -v --cov --benchmark
  # All tests must pass
  # Coverage â‰¥85%
  # Performance benchmarks met
  ```

- [ ] **Task 5.13:** ğŸ”µ Final refactoring and documentation
  - Code review and cleanup
  - Update API documentation
  - Create troubleshooting guide
  - Performance tuning recommendations

### Phase 6: Deployment & Documentation (2 days) - TDD Completion

#### Day 1: Pre-Deployment Validation & Infrastructure

- [ ] **Task 6.1:** âœ… Final TDD Validation Checklist
  ```bash
  # Verify all TDD requirements met:
  # âœ“ All unit tests passing (â‰¥85% coverage)
  # âœ“ All integration tests passing
  # âœ“ All performance benchmarks met
  # âœ“ No failing tests in CI pipeline
  # âœ“ Code review completed
  ```

- [ ] **Task 6.2:** ğŸ”´ Write deployment smoke tests
  ```python
  # Test: Lambda functions invocable via API Gateway
  # Test: DynamoDB tables accessible
  # Test: Kinesis streams receiving events
  # Test: CloudWatch logs being written
  # Test: End-to-end assignment flow works
  ```

- [ ] **Task 6.3:** ğŸŸ¢ Update CDK infrastructure stacks
  - Add Lambda function definitions (assignment, events, feature_flags)
  - Configure event sources (API Gateway, Kinesis triggers)
  - Set environment variables (LOG_LEVEL, TABLE_NAMES)
  - Configure VPC settings (if needed)
  - Add monitoring dashboards and alarms

- [ ] **Task 6.4:** ğŸŸ¢ Create deployment pipeline
  - CI/CD integration with GitHub Actions/CodePipeline
  - Automated test execution on PR
  - Blue/green deployment strategy
  - Automatic rollback on test failures
  - Deployment approval gates

#### Day 2: Staging Deployment, Testing & Documentation

- [ ] **Task 6.5:** ğŸŸ¢ Deploy to staging environment
  ```bash
  cd infrastructure/cdk
  cdk deploy --all --profile staging
  # Deploy all Lambda functions to staging
  ```

- [ ] **Task 6.6:** âœ… Run smoke tests in staging
  ```bash
  # Execute deployment smoke tests
  pytest backend/lambda/tests/smoke/ --env=staging
  # All smoke tests must pass before production
  ```

- [ ] **Task 6.7:** ğŸ”´ Write production deployment validation tests
  ```python
  # Test: Production Lambda invocation works
  # Test: Production metrics flowing to CloudWatch
  # Test: Production alarms configured correctly
  # Test: Rollback procedure works
  ```

- [ ] **Task 6.8:** ğŸŸ¢ Production deployment
  - Execute production deployment checklist
  - Deploy with gradual traffic shifting (10% â†’ 50% â†’ 100%)
  - Monitor error rates and latency during rollout
  - Run validation tests against production
  - Document deployment timestamp and version

- [ ] **Task 6.9:** âœ… Post-deployment validation
  ```bash
  # Verify production deployment:
  # âœ“ All Lambda functions healthy
  # âœ“ CloudWatch metrics reporting
  # âœ“ No error rate spikes
  # âœ“ Latency within SLAs
  # âœ“ Integration with existing services working
  ```

- [ ] **Task 6.10:** ğŸ“ Complete documentation
  - Lambda function API documentation
  - Architecture diagrams (updated with Lambda functions)
  - Operations runbook (troubleshooting, scaling, monitoring)
  - Incident response playbook
  - Performance tuning guide
  - Rollback procedures

- [ ] **Task 6.11:** ğŸ”µ Final code review and retrospective
  - Team code review session
  - Update ARCHITECTURE.md with Lambda patterns
  - Document lessons learned
  - Create follow-up tickets for improvements
  - Update project README with Lambda information

---

## âœ… Acceptance Criteria

### Functional Requirements

1. **Assignment Lambda**
   - [ ] Returns consistent variant assignments for same user+experiment
   - [ ] Respects traffic allocation percentages (Â±2% accuracy)
   - [ ] Evaluates targeting rules correctly (100% match with backend logic)
   - [ ] Stores assignments in DynamoDB with <50ms P99 latency
   - [ ] Handles errors gracefully with proper status codes

2. **Event Processor Lambda**
   - [ ] Processes Kinesis batches of 100-500 events
   - [ ] Validates and filters invalid events
   - [ ] Aggregates metrics in real-time
   - [ ] Archives events to S3 with proper partitioning
   - [ ] Handles partial batch failures without data loss

3. **Feature Flag Lambda**
   - [ ] Evaluates flags with <40ms P99 latency
   - [ ] Caches flag configurations effectively (>95% hit rate)
   - [ ] Respects rollout percentages accurately
   - [ ] Evaluates targeting rules correctly
   - [ ] Records evaluation events asynchronously

### Performance Requirements

1. **Latency**
   - [ ] Assignment Lambda: P99 < 50ms
   - [ ] Event Processor: P99 < 100ms per batch
   - [ ] Feature Flag Lambda: P99 < 40ms

2. **Throughput**
   - [ ] Assignment Lambda: 10K RPS per function
   - [ ] Event Processor: 1M events/hour
   - [ ] Feature Flag Lambda: 20K RPS per function

3. **Reliability**
   - [ ] 99.9% success rate
   - [ ] < 0.1% error rate
   - [ ] Automatic retry on failures
   - [ ] DLQ for failed messages

### Operational Requirements

1. **Monitoring**
   - [ ] CloudWatch dashboards created
   - [ ] Metrics for invocations, errors, duration
   - [ ] Custom business metrics
   - [ ] Alerts configured for errors and latency

2. **Cost**
   - [ ] Lambda cost < $500/month for 100M requests
   - [ ] Efficient memory allocation (512MB-1GB)
   - [ ] Cold start optimization

3. **Security**
   - [ ] IAM least privilege permissions
   - [ ] Encryption at rest (DynamoDB, S3)
   - [ ] Encryption in transit (TLS)
   - [ ] No hardcoded credentials

---

## âœ”ï¸ Definition of Done

### Code Quality
- [ ] All Lambda functions implemented and working
- [ ] Code follows Python PEP 8 style guidelines
- [ ] Type hints added for all functions
- [ ] Docstrings for all public functions
- [ ] No hardcoded values (use environment variables)

### Testing
- [ ] Unit tests written with >85% coverage
- [ ] Integration tests pass
- [ ] Load tests completed successfully
- [ ] Edge cases tested and handled

### Documentation
- [ ] Code documented with inline comments
- [ ] README created for each Lambda function
- [ ] API documentation updated
- [ ] Architecture diagrams updated
- [ ] Operations runbook created

### Deployment
- [ ] CDK stacks updated and tested
- [ ] CI/CD pipeline configured
- [ ] Deployed to staging environment
- [ ] Smoke tests pass in staging
- [ ] Production deployment plan created

### Monitoring
- [ ] CloudWatch dashboards created
- [ ] Metrics and logs configured
- [ ] Alerts set up and tested
- [ ] On-call runbook updated

### Review & Approval
- [ ] Code review completed by senior engineer
- [ ] Security review completed
- [ ] Performance benchmarks met
- [ ] Product owner approval
- [ ] Ready for production deployment

---

## ğŸ“Š Dependencies

### Blocked By
- None (infrastructure already exists)

### Blocking
- EP-011: Integration Testing (needs Lambda functions to test)
- EP-012: Performance & Load Testing (needs real-time services)

### Related Tickets
- EP-001: Advanced Rules Engine (shares targeting logic)
- EP-013: Monitoring & Logging (needs metrics from Lambdas)

---

## ğŸš¨ Risks & Mitigation

### Risk 1: Cold Start Latency
**Impact:** High
**Probability:** Medium
**Mitigation:**
- Use provisioned concurrency for critical functions
- Optimize package size (<50MB)
- Use Lambda SnapStart (Python 3.11)
- Implement warming strategy

### Risk 2: DynamoDB Throttling
**Impact:** High
**Probability:** Low
**Mitigation:**
- Use on-demand capacity mode
- Implement exponential backoff
- Add circuit breaker
- Monitor write capacity units

### Risk 3: Inconsistent Assignment Logic
**Impact:** Critical
**Probability:** Low
**Mitigation:**
- Share code with backend services
- Comprehensive integration tests
- Canary deployments
- A/B test Lambda vs backend

### Risk 4: Cost Overruns
**Impact:** Medium
**Probability:** Low
**Mitigation:**
- Set AWS budgets and alerts
- Monitor Lambda invocation counts
- Optimize memory and duration
- Use reserved capacity if needed

---

## ğŸ“ˆ Success Metrics

### Technical Metrics
- Assignment latency P99 < 50ms
- Event processing throughput > 1M events/hour
- Error rate < 0.1%
- Cache hit rate > 95%

### Business Metrics
- 60% reduction in infrastructure costs
- 10x improvement in scalability
- 50% reduction in assignment latency
- 99.9% uptime

---

## ğŸ“š Reference Materials

### Documentation
- [AWS Lambda Best Practices](https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html)
- [DynamoDB Best Practices](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/best-practices.html)
- [Kinesis Stream Processing](https://docs.aws.amazon.com/streams/latest/dev/building-consumers.html)

### Internal Resources
- `backend/app/core/rules_engine.py` - Rules evaluation logic
- `backend/app/services/assignment_service.py` - Assignment logic
- `infrastructure/cdk/stacks/analytics_stack.py` - Kinesis setup
- `infrastructure/cdk/stacks/compute_stack.py` - Lambda roles

### Similar Implementations
- Statsig: Consistent hashing implementation
- LaunchDarkly: Feature flag evaluation
- Optimizely: Real-time event processing

---

## ğŸ”„ Change Log

| Date       | Author | Change Description |
|------------|--------|-------------------|
| 2025-12-16 | Claude | Initial ticket creation |

---

**Estimated Completion:** 17 working days (3.5 weeks)
**Target Sprint:** Q1 2026, Sprint 3-4
